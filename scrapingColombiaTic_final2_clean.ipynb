{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3XT39Lks6Knpo7SSOIAFu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josvaldes/trabajoGradoMCD/blob/PrimeraBD/scrapingColombiaTic_final2_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb5V-IXFUfuf"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# === 1. Montar Google Drive y preparar entorno ===============\n",
        "# ============================================================\n",
        "\n",
        "from google.colab import drive\n",
        "import os, requests, shutil, re, pandas as pd, traceback\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from datetime import datetime\n",
        "import duckdb\n",
        "\n",
        "# --- Montar Google Drive ---\n",
        "drive.mount('/content/gdrive')\n",
        "base_path = \"/content/gdrive/MyDrive/trabajoGrado/Codigo/reporteColombiaTic\"\n",
        "\n",
        "# --- Crear carpetas necesarias ---\n",
        "temp_folder = os.path.join(base_path, \"temp_descargas\")\n",
        "final_folder = os.path.join(base_path, \"reportes\")\n",
        "os.makedirs(temp_folder, exist_ok=True)\n",
        "os.makedirs(final_folder, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Google Drive detectado en: /content/gdrive\")\n",
        "print(f\"üìÇ Carpeta base lista: {base_path}\")\n",
        "\n",
        "# ============================================================\n",
        "# === 2. Funciones auxiliares ================================\n",
        "# ============================================================\n",
        "\n",
        "log_file = os.path.join(base_path, \"descargas_log.csv\")\n",
        "\n",
        "def registrar_log(nombre, url, size, carpeta, estado, fallo=\"\"):\n",
        "    \"\"\"Registrar proceso de descarga en log CSV.\"\"\"\n",
        "    registro = pd.DataFrame([{\n",
        "        \"archivo\": nombre,\n",
        "        \"url\": url,\n",
        "        \"tamano_mb\": size,\n",
        "        \"ubicacion\": carpeta,\n",
        "        \"estado\": estado,\n",
        "        \"detalle\": fallo,\n",
        "        \"fecha\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }])\n",
        "    if os.path.exists(log_file):\n",
        "        registro.to_csv(log_file, mode=\"a\", header=False, index=False)\n",
        "    else:\n",
        "        registro.to_csv(log_file, index=False)\n",
        "    return registro\n",
        "\n",
        "def limpiar_nombre(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r\"[^a-z0-9√°√©√≠√≥√∫√± ]\", \"\", texto)\n",
        "    texto = texto.replace(\" \", \"_\")\n",
        "    return texto.strip(\"_\")\n",
        "\n",
        "# ============================================================\n",
        "# === 3. Conectarse al portal ColombiaTIC ====================\n",
        "# ============================================================\n",
        "\n",
        "base_url = \"https://colombiatic.mintic.gov.co/679/w3-channel.html\"\n",
        "print(f\"\\nüåê Accediendo al portal: {base_url}\")\n",
        "\n",
        "try:\n",
        "    resp = requests.get(base_url, timeout=20)\n",
        "    resp.raise_for_status()\n",
        "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
        "\n",
        "    boletin_links = [\n",
        "        (a.text.strip(), urljoin(base_url, a[\"href\"]))\n",
        "        for a in soup.find_all(\"a\", href=True)\n",
        "        if \"w3-article\" in a[\"href\"]\n",
        "    ]\n",
        "\n",
        "    print(f\"üì∞ Se encontraron {len(boletin_links)} boletines publicados.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è No se pudo acceder al portal ({e}).\")\n",
        "    boletin_links = []\n",
        "\n",
        "# ============================================================\n",
        "# === 4. Descargar archivos relevantes =======================\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nüì° Analizando boletines...\")\n",
        "\n",
        "for titulo, boletin_url in boletin_links:\n",
        "    # Solo boletines del sector TIC\n",
        "    if \"tic\" not in titulo.lower():\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nüîé Revisando bolet√≠n: {titulo}\")\n",
        "        res = requests.get(boletin_url, timeout=20)\n",
        "        res.raise_for_status()\n",
        "        s = BeautifulSoup(res.text, \"lxml\")\n",
        "\n",
        "        for a in s.find_all(\"a\", href=True):\n",
        "            href = a[\"href\"]\n",
        "            if href.lower().endswith((\".xlsx\", \".xls\")):\n",
        "                file_url = urljoin(boletin_url, href)\n",
        "                nombre_archivo = limpiar_nombre(titulo) + \".xlsx\"\n",
        "                ruta_temp = os.path.join(temp_folder, nombre_archivo)\n",
        "\n",
        "                # Evitar duplicados\n",
        "                if os.path.exists(os.path.join(final_folder, nombre_archivo)):\n",
        "                    print(f\"‚è≠Ô∏è Ya existe: {nombre_archivo}, se omite descarga.\")\n",
        "                    continue\n",
        "\n",
        "                # Tama√±o del archivo\n",
        "                head = requests.head(file_url, timeout=20)\n",
        "                size_mb = int(head.headers.get(\"Content-Length\", 0)) / (1024 * 1024)\n",
        "\n",
        "                if size_mb > 150:\n",
        "                    print(f\"‚è≠Ô∏è Saltando {nombre_archivo} (archivo grande: {size_mb:.1f} MB)\")\n",
        "                    registrar_log(nombre_archivo, file_url, size_mb, \"temp_descargas\", \"omitido\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"‚¨áÔ∏è Descargando: {nombre_archivo} ({size_mb:.1f} MB)\")\n",
        "                r = requests.get(file_url, timeout=60)\n",
        "                r.raise_for_status()\n",
        "                with open(ruta_temp, \"wb\") as f:\n",
        "                    f.write(r.content)\n",
        "                print(f\"‚úÖ Guardado temporalmente: {ruta_temp}\")\n",
        "                registrar_log(nombre_archivo, file_url, size_mb, \"temp_descargas\", \"descargado\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error en bolet√≠n {titulo}: {e}\")\n",
        "        registrar_log(titulo, boletin_url, 0, \"temp_descargas\", \"error\", f\"{e}\")\n",
        "\n",
        "# ============================================================\n",
        "# === 5. Mover archivos v√°lidos a carpeta final ===============\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nüîç Validando archivos descargados...\")\n",
        "archivos_temp = [f for f in os.listdir(temp_folder) if f.lower().endswith((\".xlsx\", \".xls\"))]\n",
        "print(f\"üì¶ Total archivos temporales: {len(archivos_temp)}\")\n",
        "\n",
        "for archivo in archivos_temp:\n",
        "    shutil.move(os.path.join(temp_folder, archivo), os.path.join(final_folder, archivo))\n",
        "    registrar_log(archivo, \"-\", 0, \"reportes\", \"movido_a_final\")\n",
        "\n",
        "# Eliminar carpeta temporal si est√° vac√≠a\n",
        "if not os.listdir(temp_folder):\n",
        "    os.rmdir(temp_folder)\n",
        "    print(\"üß∫ Carpeta temporal vac√≠a eliminada.\")\n",
        "\n",
        "print(f\"\\nüìÅ Carpeta final lista para procesamiento: {final_folder}\")\n",
        "print(f\"üßæ Log actualizado: {log_file}\")\n",
        "\n",
        "# ============================================================\n",
        "# === 6. Cargar archivos Excel en DuckDB (resiliente) =========\n",
        "# ============================================================\n",
        "\n",
        "db_path = \"/content/gdrive/MyDrive/trabajoGrado/reporteColombiaTic.db\"\n",
        "backup_path = \"/content/gdrive/MyDrive/trabajoGrado/reporteColombiaTic_backup.db\"\n",
        "\n",
        "def conectar_duckdb_seguro(ruta):\n",
        "    \"\"\"Intenta conectar a DuckDB y reconstruir si la base est√° da√±ada.\"\"\"\n",
        "    try:\n",
        "        con = duckdb.connect(ruta)\n",
        "        con.execute(\"PRAGMA version;\").fetchall()\n",
        "        print(f\"‚úÖ Base verificada: {ruta}\")\n",
        "        return con\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al abrir la base ({e}). Intentando reparar...\")\n",
        "        if os.path.exists(ruta):\n",
        "            shutil.move(ruta, backup_path)\n",
        "            if os.path.exists(ruta + \".wal\"):\n",
        "                os.remove(ruta + \".wal\")\n",
        "            print(f\"üóÇÔ∏è Copia de seguridad creada: {backup_path}\")\n",
        "        con = duckdb.connect(ruta)\n",
        "        print(f\"üÜï Nueva base creada en: {ruta}\")\n",
        "        return con\n",
        "\n",
        "con = conectar_duckdb_seguro(db_path)\n",
        "\n",
        "# üîπ Crear una secuencia (contador autom√°tico)\n",
        "con.execute(\"CREATE SEQUENCE IF NOT EXISTS seq_control START 1;\")\n",
        "\n",
        "# üîπ Crear tabla con ID autogenerado usando la secuencia\n",
        "con.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS control_cargue (\n",
        "    id BIGINT PRIMARY KEY DEFAULT nextval('seq_control'),\n",
        "    archivo VARCHAR,\n",
        "    hoja VARCHAR,\n",
        "    columnas_detectadas VARCHAR,\n",
        "    filas INTEGER,\n",
        "    fecha_cargue TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================\n",
        "# === Reparar tabla control_cargue si tiene definici√≥n vieja ==\n",
        "# ============================================================\n",
        "\n",
        "try:\n",
        "    tabla_info = con.execute(\"PRAGMA table_info('control_cargue')\").df()\n",
        "    if 'id' not in tabla_info['name'].tolist():\n",
        "        raise Exception(\"Tabla control_cargue inv√°lida (sin campo id).\")\n",
        "\n",
        "    # Verificar si la columna id tiene un default autoincremental\n",
        "    if not any(\"nextval\" in str(d) for d in tabla_info['dflt_value']):\n",
        "        print(\"‚ö†Ô∏è Tabla control_cargue sin secuencia de autoincremento. Corrigiendo...\")\n",
        "\n",
        "        # Respaldar datos antiguos si existen\n",
        "        try:\n",
        "            df_old = con.execute(\"SELECT * FROM control_cargue\").df()\n",
        "        except:\n",
        "            df_old = pd.DataFrame()\n",
        "\n",
        "        # Eliminar tabla vieja\n",
        "        con.execute(\"DROP TABLE IF EXISTS control_cargue;\")\n",
        "        con.execute(\"DROP SEQUENCE IF EXISTS seq_control;\")\n",
        "\n",
        "        # Crear secuencia e tabla nuevas\n",
        "        con.execute(\"CREATE SEQUENCE IF NOT EXISTS seq_control START 1;\")\n",
        "        con.execute(\"\"\"\n",
        "        CREATE TABLE control_cargue (\n",
        "            id BIGINT PRIMARY KEY DEFAULT nextval('seq_control'),\n",
        "            archivo VARCHAR,\n",
        "            hoja VARCHAR,\n",
        "            columnas_detectadas VARCHAR,\n",
        "            filas INTEGER,\n",
        "            fecha_cargue TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "        # Restaurar datos antiguos (si exist√≠an)\n",
        "        if not df_old.empty:\n",
        "            con.append(\"control_cargue\", df_old)\n",
        "            print(f\"‚úÖ Tabla control_cargue reparada y restaurados {len(df_old)} registros.\")\n",
        "        else:\n",
        "            print(\"‚úÖ Tabla control_cargue creada desde cero (no hab√≠a datos previos).\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚úÖ Tabla control_cargue ya tiene secuencia de autoincremento.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è No exist√≠a tabla control_cargue, creando nueva... ({e})\")\n",
        "\n",
        "    con.execute(\"DROP SEQUENCE IF EXISTS seq_control;\")\n",
        "    con.execute(\"CREATE SEQUENCE IF NOT EXISTS seq_control START 1;\")\n",
        "    con.execute(\"\"\"\n",
        "    CREATE TABLE control_cargue (\n",
        "        id BIGINT PRIMARY KEY DEFAULT nextval('seq_control'),\n",
        "        archivo VARCHAR,\n",
        "        hoja VARCHAR,\n",
        "        columnas_detectadas VARCHAR,\n",
        "        filas INTEGER,\n",
        "        fecha_cargue TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "    )\n",
        "    \"\"\")\n",
        "    print(\"‚úÖ Tabla control_cargue creada correctamente.\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Cargar solo archivos nuevos ---\n",
        "archivos_finales = [f for f in os.listdir(final_folder) if f.lower().endswith((\".xlsx\", \".xls\"))]\n",
        "print(f\"\\nüì¶ Archivos Excel disponibles: {len(archivos_finales)}\")\n",
        "\n",
        "try:\n",
        "    ya_cargados = set(con.execute(\"SELECT DISTINCT archivo FROM control_cargue\").fetchdf()[\"archivo\"].tolist())\n",
        "except:\n",
        "    ya_cargados = set()\n",
        "\n",
        "archivos_nuevos = [f for f in archivos_finales if f not in ya_cargados]\n",
        "\n",
        "if not archivos_nuevos:\n",
        "    print(\"‚è≠Ô∏è No hay archivos nuevos para cargar. La base est√° actualizada.\")\n",
        "else:\n",
        "    print(f\"üÜï Archivos nuevos detectados: {len(archivos_nuevos)}\")\n",
        "    for nombre_archivo in archivos_nuevos:\n",
        "        ruta_archivo = os.path.join(final_folder, nombre_archivo)\n",
        "        print(f\"\\nüìò Procesando archivo nuevo: {nombre_archivo}\")\n",
        "\n",
        "        try:\n",
        "            xls = pd.ExcelFile(ruta_archivo)\n",
        "            hojas_excel = xls.sheet_names\n",
        "            print(f\"   üßæ Hojas detectadas: {hojas_excel[:10]}...\")\n",
        "\n",
        "            for hoja in hojas_excel:\n",
        "                for fila_encabezado in range(0, 10):\n",
        "                    df = pd.read_excel(ruta_archivo, sheet_name=hoja, header=fila_encabezado)\n",
        "                    if df.columns.notna().sum() > 2:\n",
        "                        break\n",
        "\n",
        "                nombre_archivo_base = os.path.splitext(nombre_archivo)[0].lower()\n",
        "                nombre_archivo_base = re.sub(r\"[^a-z0-9_]\", \"\", nombre_archivo_base)\n",
        "                nombre_hoja_normalizada = re.sub(r\"[^a-z0-9_]\", \"\", hoja.lower())\n",
        "                nombre_tabla = f\"{nombre_archivo_base}_{nombre_hoja_normalizada}\"\n",
        "\n",
        "                print(f\"   üìä Cargando hoja '{hoja}' como tabla '{nombre_tabla}' ({len(df)} filas)\")\n",
        "                # ‚úÖ Convertir todas las columnas a texto para evitar errores de tipo\n",
        "                df = df.astype(str)\n",
        "\n",
        "                # Crear la tabla en DuckDB\n",
        "                try:\n",
        "                    con.execute(f\"CREATE OR REPLACE TABLE '{nombre_tabla}' AS SELECT * FROM df\")\n",
        "                    print(f\"   ‚úÖ Tabla creada: {nombre_tabla} ({len(df)} filas)\")\n",
        "\n",
        "                    # Registrar en control_cargue\n",
        "                    con.execute(\"\"\"\n",
        "                        INSERT INTO control_cargue (archivo, hoja, columnas_detectadas, filas)\n",
        "                        VALUES (?, ?, ?, ?)\n",
        "                    \"\"\", [nombre_archivo, hoja, \", \".join(map(str, df.columns)), len(df)])\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"   ‚ö†Ô∏è Error al crear tabla {nombre_tabla}: {e}\")\n",
        "\n",
        "                # ‚úÖ Insert corregido: deja que DuckDB genere autom√°ticamente el ID\n",
        "                con.execute(\"\"\"\n",
        "                    INSERT INTO control_cargue (archivo, hoja, columnas_detectadas, filas)\n",
        "                    VALUES (?, ?, ?, ?)\n",
        "                \"\"\", [nombre_archivo, hoja, \", \".join(map(str, df.columns)), len(df)])\n",
        "\n",
        "            print(f\"‚úÖ Archivo '{nombre_archivo}' cargado completamente.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error procesando {nombre_archivo}: {e}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "print(\"\\nüìä Tablas actuales en la base:\")\n",
        "print(con.execute(\"SHOW TABLES\").df())\n",
        "\n",
        "print(\"\\nüìã Estado de control_cargue:\")\n",
        "print(con.execute(\"\"\"\n",
        "    SELECT archivo, COUNT(*) hojas_cargadas, SUM(filas) filas_totales\n",
        "    FROM control_cargue\n",
        "    GROUP BY archivo\n",
        "    ORDER BY archivo\n",
        "\"\"\").df())\n",
        "\n",
        "con.close()\n",
        "print(\"\\nüéØ Base validada, actualizada y lista para an√°lisis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "con = conectar_duckdb_seguro(db_path)\n",
        "\n",
        "print(con.execute(\"SELECT * FROM control_cargue ORDER BY fecha_cargue DESC\").df())\n",
        "\n",
        "con.close()\n"
      ],
      "metadata": {
        "id": "adu4VJTZWQra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}